"""10-ì—ì´ì „íŠ¸ ê²½ìŸ ì¹´ë“œë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ëª¨ë“ˆ

5ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ ê° 2ê°œ ì•„ì´ë””ì–´ = 10ê°œ ì•„ì´ë””ì–´ ìƒì„± í›„
5ê°œ ê¸°ì¤€ ê²½ìŸ í‰ê°€ â†’ Top 2 ì„ ì • â†’ í’€ ìŠ¤í¬ë¦½íŠ¸ + ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ + Description Mention ìƒì„±
"""

import json
import logging
import os
import re
import time
import xml.etree.ElementTree as ET
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from difflib import SequenceMatcher
from pathlib import Path

import requests as _requests

logger = logging.getLogger(__name__)

# â”€â”€ íˆìŠ¤í† ë¦¬ íŒŒì¼ â”€â”€
HISTORY_FILE = Path(__file__).parent / "cardnews_history.json"

# â”€â”€ ì—ì´ì „íŠ¸ ì •ì˜ â”€â”€
AGENTS = [
    {
        "id": "season",
        "name": "ê³„ì ˆê±´ê°• ì—ì´ì „íŠ¸",
        "domain": "ê³„ì ˆÂ·ì ˆê¸°Â·ê¸°í›„ ë³€í™”ì— ë”°ë¥¸ ê±´ê°• ê´€ë¦¬",
        "search_hint": "ê³„ì ˆ ê±´ê°• íŠ¸ë Œë“œ, ì ˆê¸°ë³„ ì–‘ìƒë²•, ê¸°í›„ ë³€í™”ì™€ ê±´ê°•",
    },
    {
        "id": "social",
        "name": "ì†Œì…œíŠ¸ë Œë“œ ì—ì´ì „íŠ¸",
        "domain": "SNS ê±´ê°• íŠ¸ë Œë“œ, ë°”ì´ëŸ´ ì´ìŠˆ, MZì„¸ëŒ€ ê±´ê°• ê´€ì‹¬ì‚¬",
        "search_hint": "ê±´ê°• ë°”ì´ëŸ´ íŠ¸ë Œë“œ, MZ ê±´ê°• SNS, ê±´ê°• ë°ˆ",
    },
    {
        "id": "history",
        "name": "ì—­ì‚¬ê±´ê°• ì—ì´ì „íŠ¸",
        "domain": "ì—­ì‚¬ ì¸ë¬¼Â·ì‚¬ê±´ê³¼ í•œì˜í•™ ì—°ê²°, ë™ì˜ë³´ê°, ê¶ì¤‘ ë¹„ë°©",
        "search_hint": "í•œì˜í•™ ì—­ì‚¬, ë™ì˜ë³´ê° SNS ì¸ê¸°, ì¡°ì„  ê±´ê°• ì´ì•¼ê¸°",
    },
    {
        "id": "women",
        "name": "ì—¬ì„±ê±´ê°• ì—ì´ì „íŠ¸",
        "domain": "ì—¬ì„± ê±´ê°•, í˜¸ë¥´ëª¬, ì´ë„ˆë·°í‹°, ê°±ë…„ê¸°, ì‚°í›„ ê´€ë¦¬",
        "search_hint": "ì—¬ì„± ê±´ê°• íŠ¸ë Œë“œ, ì´ë„ˆë·°í‹°, ê°±ë…„ê¸° ê´€ë¦¬",
    },
    {
        "id": "worker",
        "name": "ì§ì¥ì¸ê±´ê°• ì—ì´ì „íŠ¸",
        "domain": "ì§ì¥ì¸ í”¼ë¡œ, ë²ˆì•„ì›ƒ, ìˆ˜ë©´ ë¶€ì¡±, ì‚¬ë¬´ì§ ê±´ê°• ë¬¸ì œ",
        "search_hint": "ì§ì¥ì¸ ê±´ê°• íŠ¸ë Œë“œ, ë²ˆì•„ì›ƒ ìˆ˜ë©´, ì‚¬ë¬´ì§ ê±´ê°•",
    },
]

# â”€â”€ ì¹´í…Œê³ ë¦¬ â”€â”€
CATEGORIES = [
    {"id": "korean_medicine", "name": "í•œì˜í•™ ì§€ì‹", "desc": "ì „í†µ í•œì˜í•™ ì´ë¡ , ì²˜ë°©, ê²½ë½, ì²´ì§ˆ"},
    {"id": "historical_story", "name": "ì—­ì‚¬ ìŠ¤í† ë¦¬í…”ë§", "desc": "ì—­ì‚¬ ì¸ë¬¼ ì—í”¼ì†Œë“œ, ê¶ì¤‘ ë¹„ë°©"},
    {"id": "health_tips", "name": "ê±´ê°• ìƒì‹", "desc": "í˜„ëŒ€ì¸ ì‹¤ìš© ê±´ê°• ì •ë³´"},
    {"id": "seasonal_health", "name": "ê³„ì ˆ ê±´ê°•", "desc": "24ì ˆê¸°, ê³„ì ˆë³„ ê±´ê°• ê´€ë¦¬"},
    {"id": "food_medicine", "name": "ì‹í’ˆ ì •ë³´", "desc": "ì•½ì‹ë™ì›, ê±´ê°• ì‹ì¬ë£Œ"},
]

# â”€â”€ íŒ¨í„´ â”€â”€
PATTERNS = [
    {"id": "question", "name": "ì§ˆë¬¸í˜•", "template": "[ì˜ë¬¸ì‚¬] + [êµ¬ì²´ì  ìƒí™©]?", "tone": "í˜¸ê¸°ì‹¬ ìœ ë°œ"},
    {"id": "surprise", "name": "ë†€ë¼ì›€í˜•", "template": "[ì¹œìˆ™í•œ ì†Œì¬] + [ì¶©ê²©ì  ìˆ˜ì¹˜]!", "tone": "ì¶©ê²©, ë°˜ì „"},
    {"id": "historical", "name": "ì—­ì‚¬í˜•", "template": "[ì—­ì‚¬ ì¸ë¬¼/ì‹œëŒ€] + [ê±´ê°• ì´ì•¼ê¸°]", "tone": "ê¶Œìœ„, ìŠ¤í† ë¦¬í…”ë§"},
    {"id": "fear", "name": "ê³µí¬í˜•", "template": "[í˜„ì¬ ì¦ìƒ] + [ë¯¸ë˜ ìœ„í—˜]ì„ ë¶€ë¥¸ë‹¤?", "tone": "ê²½ê°ì‹¬"},
    {"id": "practical", "name": "ì‹¤ìš©í˜•", "template": "[ìƒí™©] + [ì‹¤í–‰ ë°©ë²•]!", "tone": "ì¹œì ˆ, ì‹¤ìš©ì„±"},
    {"id": "doubt", "name": "ì˜ë¬¸í˜•", "template": "[í†µë…] + ì‚¬ì‹¤ì€ [ì§„ì‹¤]?", "tone": "í˜¸ê¸°ì‹¬, ë°˜ì „"},
    {"id": "plan", "name": "ê³„íší˜•", "template": "[ê¸°ê°„] + [ê±´ê°• ëª©í‘œ] í”„ë¡œì íŠ¸", "tone": "ë™ê¸°ë¶€ì—¬"},
    {"id": "statistics", "name": "í†µê³„í˜•", "template": "[ëŒ€ìƒ] [%]ê°€ ê²ªëŠ” + [ì´ìŠˆ]", "tone": "ì‹ ë¢°, ê°ê´€ì„±"},
]

# â”€â”€ ê³„ì ˆ/ì ˆê¸° â”€â”€
SEASONS = {
    "spring": {"months": [3, 4, 5], "kr": "ë´„", "theme": "í•´ë…ê³¼ í™œë ¥"},
    "summer": {"months": [6, 7, 8], "kr": "ì—¬ë¦„", "theme": "ë³´ì–‘ê³¼ ìˆ˜ë¶„"},
    "autumn": {"months": [9, 10, 11], "kr": "ê°€ì„", "theme": "ë©´ì—­ê³¼ ê±´ì¡° ëŒ€ë¹„"},
    "winter": {"months": [12, 1, 2], "kr": "ê²¨ìš¸", "theme": "ë³´ì˜¨ê³¼ í˜ˆì•¡ìˆœí™˜"},
}

SOLAR_TERMS = [
    ("02-04", "ì…ì¶˜"), ("02-19", "ìš°ìˆ˜"), ("03-06", "ê²½ì¹©"), ("03-21", "ì¶˜ë¶„"),
    ("04-05", "ì²­ëª…"), ("04-20", "ê³¡ìš°"), ("05-06", "ì…í•˜"), ("05-21", "ì†Œë§Œ"),
    ("06-06", "ë§ì¢…"), ("06-21", "í•˜ì§€"), ("07-07", "ì†Œì„œ"), ("07-23", "ëŒ€ì„œ"),
    ("08-08", "ì…ì¶”"), ("08-23", "ì²˜ì„œ"), ("09-08", "ë°±ë¡œ"), ("09-23", "ì¶”ë¶„"),
    ("10-08", "í•œë¡œ"), ("10-24", "ìƒê°•"), ("11-07", "ì…ë™"), ("11-22", "ì†Œì„¤"),
    ("12-07", "ëŒ€ì„¤"), ("12-22", "ë™ì§€"), ("01-06", "ì†Œí•œ"), ("01-20", "ëŒ€í•œ"),
]

# â”€â”€ ì‹ì•½ì²˜ ê·œì œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ â”€â”€
REGULATORY_BLACKLIST = [
    "ì¹˜ë£Œ", "ì™„ì¹˜", "íŠ¹íš¨ì•½", "ë§Œë³‘í†µì¹˜", "ê¸°ì ì˜",
    "ì•” ì˜ˆë°©", "ì•” ì¹˜ë£Œ", "ë‹¹ë‡¨ ì¹˜ë£Œ", "ê³ í˜ˆì•• ì¹˜ë£Œ",
    "100% íš¨ê³¼", "ë¶€ì‘ìš© ì—†ëŠ”", "FDA ìŠ¹ì¸",
    "ì•½íš¨", "ì²˜ë°©ì „", "ì§„ë‹¨", "ìˆ˜ìˆ  ëŒ€ì‹ ",
]

# â”€â”€ ë¸Œëœë“œ í´ë¡œì§• (ê³ ì •) â”€â”€
BRAND_CLOSING = "ë” ì˜¤ë˜, ë” ê±´ê°•í•˜ê²Œ. í•œì˜ì‚¬ê°€ ë§Œë“œëŠ” í•œì˜ ë¸Œëœë“œ"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê³„ì ˆ/ì ˆê¸° ê°ì§€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_season():
    """í˜„ì¬ ë‚ ì§œ ê¸°ë°˜ ê³„ì ˆ + ì ˆê¸° ê°ì§€"""
    now = datetime.now()
    month = now.month
    md = now.strftime("%m-%d")

    season_id = "winter"
    for sid, info in SEASONS.items():
        if month in info["months"]:
            season_id = sid
            break

    solar_term = None
    for date_str, term in SOLAR_TERMS:
        if md >= date_str:
            solar_term = term
        else:
            break

    return {
        "season": season_id,
        "season_kr": SEASONS[season_id]["kr"],
        "theme": SEASONS[season_id]["theme"],
        "solar_term": solar_term,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹œì¦Œ/íŠ¸ë Œë“œ ê¸°ë°˜ ì£¼ì œ ì œì•ˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ì ˆê¸°Â·ì‹œì¦Œë³„ ì£¼ì œ í’€ (ë‚ ì§œ ë²”ìœ„ â†’ ì¶”ì²œ ì£¼ì œë“¤)
_SEASONAL_TOPICS = {
    # ê²¨ìš¸ (12~2ì›”)
    "winter": [
        "ê²¨ìš¸ í•œíŒŒì™€ í˜ˆì•¡ìˆœí™˜ì˜ ê´€ê³„",
        "ì¡°ì„  ì™•ì‹¤ì˜ ê²¨ìš¸ë‚˜ê¸° ë¹„ë²•",
        "ì„¤ë‚  ê³¼ì‹ í›„ ì†Œí™” ë•ëŠ” í•œë°© ì–‘ìƒë²•",
        "ê²¨ìš¸ì  ìëŠ” ë™ë¬¼ vs ë¶ˆë©´ì¦ í˜„ëŒ€ì¸",
        "ë™ì§€ íŒ¥ì£½ì˜ í•œì˜í•™ì  ë¹„ë°€",
    ],
    # ë´„ (3~5ì›”)
    "spring": [
        "ì¶˜ê³¤ì¦, ì•Œê³  ë³´ë©´ ê°„(è‚)ì˜ SOS ì‹ í˜¸",
        "ë²šê½ƒ ì‹œì¦Œ ì•Œë ˆë¥´ê¸°ì™€ í•œì˜í•™",
        "ë´„ë‚˜ë¬¼ì´ ì•½ì¸ ì´ìœ  â€” ë™ì˜ë³´ê° ì† ì‚°ì±„",
        "í™©ì‚¬Â·ë¯¸ì„¸ë¨¼ì§€ ì‹œì¦Œ, ì¡°ì„ ì‹œëŒ€ì—” ì–´ë–»ê²Œ ë§‰ì•˜ì„ê¹Œ",
        "ì…ì¶˜ ì–‘ìƒë²•: ê²¨ìš¸ ë…ì†Œ í•´ë… í”„ë¡œì íŠ¸",
    ],
    # ì—¬ë¦„ (6~8ì›”)
    "summer": [
        "ì‚¼ë³µë”ìœ„ì— ì™œ ì‚¼ê³„íƒ•? í•œì˜í•™ì  ì´ìœ ",
        "ì—ì–´ì»¨ë³‘ì˜ ì •ì²´ â€” ëƒ‰ë°©ì´ ê¸°í˜ˆì„ ë§‰ëŠ” ì›ë¦¬",
        "ì¡°ì„  ì™•ì´ ì—¬ë¦„ì— ë§ˆì‹  íŠ¹ë³„í•œ ìŒë£Œ",
        "ì—´ëŒ€ì•¼ ë¶ˆë©´ì¦, í•œì˜í•™ì˜ ì‹¬ì—´(å¿ƒç†±) ì´ë¡ ",
        "ì—¬ë¦„ ë³´ì–‘ì‹ì˜ ì§„ì§œ íš¨ê³¼ â€” ë™ì˜ë³´ê° ê¸°ë¡",
    ],
    # ê°€ì„ (9~11ì›”)
    "autumn": [
        "ê°€ì„ ê±´ì¡°í•¨ì´ íë¥¼ ê³µê²©í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜",
        "ì¶”ì„ ëª…ì ˆ í›„ìœ ì¦, í•œì˜í•™ì  í•´ê²°ë²•",
        "ë‹¨í’ì´ ë“œëŠ” ì´ìœ ì™€ ìš°ë¦¬ ëª¸ì˜ ë…¸í™”",
        "í™˜ì ˆê¸° ë©´ì—­ë ¥, ê²½ì˜¥ê³ ê°€ ì¡°ì„  ì™•ì‹¤ì—ì„œ ì“°ì¸ ì´ìœ ",
        "ê°€ì„ ìš°ìš¸ì¦(ç§‹é¬±)ì˜ í•œì˜í•™ì  í•´ì„",
    ],
}

# ì ˆê¸°ë³„ íŠ¹í™” ì£¼ì œ
_SOLAR_TERM_TOPICS = {
    "ì…ì¶˜": "ì…ì¶˜ ì–‘ìƒë²• â€” ë´„ ê¸°ìš´ ë§ì´ í•´ë…",
    "ìš°ìˆ˜": "ìš°ìˆ˜(é›¨æ°´) ì ˆê¸°, ëª¸ ì† ìˆ˜ë¶„ ë°¸ëŸ°ìŠ¤",
    "ê²½ì¹©": "ê²½ì¹©ì— ê¹¨ì–´ë‚˜ëŠ” ê±´ ë²Œë ˆë¿? ìš°ë¦¬ ëª¸ë„ ê¹¨ì›Œì•¼ í•  ë•Œ",
    "ì¶˜ë¶„": "ë‚®ë°¤ ê°™ì•„ì§€ëŠ” ì¶˜ë¶„, ìŒì–‘ ë°¸ëŸ°ìŠ¤ì™€ ê±´ê°•",
    "ì²­ëª…": "ì²­ëª… ì ˆê¸°, í•œì˜í•™ì—ì„œ ë§í•˜ëŠ” 'ë§‘ì€ ê¸°ìš´'ì´ë€",
    "ê³¡ìš°": "ê³¡ìš°(ç©€é›¨) â€” ë´„ë¹„ê°€ ì•½ì´ ë˜ëŠ” ì´ìœ ",
    "ì…í•˜": "ì…í•˜, ì—¬ë¦„ ì‹œì‘ ì „ ì²´ë ¥ ë¹„ì¶• ì „ëµ",
    "ì†Œë§Œ": "ì†Œë§Œ ì ˆê¸° â€” í•œì˜ì‚¬ê°€ ì¶”ì²œí•˜ëŠ” ì´ˆì—¬ë¦„ ì–‘ìƒ",
    "ë§ì¢…": "ë§ì¢…(èŠ’ç¨®) â€” ì”¨ ë¿Œë¦¬ë“¯ ê±´ê°•ë„ ë¯¸ë¦¬ ì¤€ë¹„",
    "í•˜ì§€": "í•˜ì§€, ë‚®ì´ ê°€ì¥ ê¸´ ë‚ ì˜ ê±´ê°• ê´€ë¦¬ë²•",
    "ì†Œì„œ": "ì†Œì„œ ë”ìœ„ ì‹œì‘, ì¡°ì„  ê¶ì¤‘ì˜ ì—¬ë¦„ ê±´ê°•ë²•",
    "ëŒ€ì„œ": "ëŒ€ì„œ í­ì—¼, í•œì˜í•™ì˜ 'ì´ì—´ì¹˜ì—´' ì§„ì§œ ì›ë¦¬",
    "ì…ì¶”": "ì…ì¶”, ê°€ì„ ëŒ€ë¹„ ë©´ì—­ë ¥ ì¶©ì „ íƒ€ì´ë°",
    "ì²˜ì„œ": "ì²˜ì„œ â€” ë”ìœ„ê°€ ê°€ê³  ê±´ì¡°í•¨ì´ ì˜¤ëŠ” ì‹œê¸°ì˜ ì–‘ìƒ",
    "ë°±ë¡œ": "ë°±ë¡œ ì´ìŠ¬ ë‚´ë¦¬ëŠ” ì ˆê¸°, í ê±´ê°• ì²´í¬ë¦¬ìŠ¤íŠ¸",
    "ì¶”ë¶„": "ì¶”ë¶„, ìŒì–‘ ì „í™˜ê¸°ì˜ ëª¸ ê´€ë¦¬ë²•",
    "í•œë¡œ": "í•œë¡œ ì°¬ ì´ìŠ¬ ì ˆê¸°, ê´€ì ˆ ê±´ê°• ì£¼ì˜ë³´",
    "ìƒê°•": "ìƒê°• ì„œë¦¬ ë‚´ë¦¬ëŠ” ì ˆê¸°, í˜ˆì•¡ìˆœí™˜ ì ê²€",
    "ì…ë™": "ì…ë™, ê²¨ìš¸ ì¤€ë¹„ â€” í•œì˜í•™ ë³´ì˜¨ ì–‘ìƒë²•",
    "ì†Œì„¤": "ì†Œì„¤ ì²«ëˆˆ ì ˆê¸°, ì‹ ì¥(è…) ë³´ì–‘ì˜ ì‹œì‘",
    "ëŒ€ì„¤": "ëŒ€ì„¤ â€” í° ëˆˆ ë‚´ë¦¬ëŠ” ì‹œê¸°, ë¼ˆÂ·ê´€ì ˆ ê±´ê°•",
    "ë™ì§€": "ë™ì§€ íŒ¥ì£½ì˜ í•œì˜í•™ì  ë¹„ë°€",
    "ì†Œí•œ": "ì†Œí•œ â€” 1ë…„ ì¤‘ ê°€ì¥ ì¶”ìš´ ì ˆê¸°ì˜ ì–‘ìƒë²•",
    "ëŒ€í•œ": "ëŒ€í•œ ê°•ì¶”ìœ„, í•œì˜í•™ í˜ˆì•¡ìˆœí™˜ ê´€ë¦¬",
}

# ì‹œì˜ì„± ìˆëŠ” ì´ë²¤íŠ¸/íŠ¸ë Œë“œ ì£¼ì œ (ì¶œì²˜ ê²€ì¦ ê°€ëŠ¥í•œ ê²ƒë§Œ ìˆ˜ë¡)
_TRENDING_TOPICS = [
    "ë™ì˜ë³´ê°ì— 358íšŒ ê¸°ë¡ëœ ê²½ì˜¥ê³ , ì¡°ì„  ì™•ì‹¤ì˜ ë³´ì•½",  # ì¶œì²˜: ìŠ¹ì •ì›ì¼ê¸°
    "ìƒ¤ë„¬ No.5ì™€ ê³µì§„ë‹¨ì˜ ê³µí†µ ì›ë£Œ 'ì‚¬í–¥'ì˜ ë¹„ë°€",  # ì¶œì²˜: ì‚¬í–¥(Musk) ì„±ë¶„ ì‚¬ì‹¤
    "ë™ì˜ë³´ê°ì´ ìœ ë„¤ìŠ¤ì½” ì„¸ê³„ê¸°ë¡ìœ ì‚°ì´ ëœ ì´ìœ ",  # ì¶œì²˜: ìœ ë„¤ìŠ¤ì½” 2009ë…„ ë“±ì¬
    "í—ˆì¤€ì´ ì“´ ì²˜ë°©ì „, 400ë…„ ë’¤ í˜„ëŒ€ ê³¼í•™ì´ ê²€ì¦í•˜ë‹¤",  # ì¶œì²˜: ë™ì˜ë³´ê° ì—°êµ¬ ë…¼ë¬¸
    "ì¼ë³¸ 'ê°í¬'ì˜ ì›ì¡°ê°€ í•œêµ­ í•œì•½ì´ë¼ëŠ” ì‚¬ì‹¤",  # ì¶œì²˜: ì¼ë³¸ í•œë°©ì˜í•™ ì—­ì‚¬
    "ì˜ì¡° 83ì„¸ ì¥ìˆ˜ ë¹„ê²°, ìŠ¹ì •ì›ì¼ê¸°ê°€ ë°íŒ ê±´ê°• ìŠµê´€",  # ì¶œì²˜: ìŠ¹ì •ì›ì¼ê¸° ê¸°ë¡
    "ì„¸ê³„ë³´ê±´ê¸°êµ¬(WHO)ê°€ ì¸ì •í•œ ì „í†µì˜í•™ ë¶„ë¥˜ ì²´ê³„",  # ì¶œì²˜: WHO ICD-11 (2019)
    "ì¡°ì„ ì‹œëŒ€ ê³¼ê±°ì‹œí—˜ ìˆ˜í—˜ìƒì˜ ì»¨ë””ì…˜ ê´€ë¦¬ë²•",  # ì¶œì²˜: ì¡°ì„  ë¬¸í—Œ ê¸°ë¡
    "ì»¤í”¼ ëŒ€ì‹  í•œë°©ì°¨, ì¹´í˜ì¸ ì—†ì´ ì§‘ì¤‘ë ¥ ë†’ì´ëŠ” ì›ë¦¬",  # ì¼ë°˜ ê±´ê°• ìƒì‹
    "í˜„ëŒ€ì¸ì˜ ëƒ‰ë°©ë³‘, ë™ì˜ë³´ê°ì— ì´ë¯¸ ë‹µì´ ìˆì—ˆë‹¤",  # ì¶œì²˜: ë™ì˜ë³´ê° ìƒí•œë¡ 
]


def suggest_topics() -> list[dict]:
    """í˜„ì¬ ì‹œì¦Œ/ì ˆê¸°/íŠ¸ë Œë“œ ê¸°ë°˜ ì£¼ì œ ì¶”ì²œ ëª©ë¡ ë°˜í™˜

    Returns: [{"label": "í‘œì‹œ í…ìŠ¤íŠ¸", "topic": "ì£¼ì œ íŒíŠ¸ ê°’", "tag": "ì‹œì¦Œ/ì ˆê¸°/íŠ¸ë Œë“œ"}, ...]
    """
    season = detect_season()
    suggestions = []

    # 1) ì ˆê¸° íŠ¹í™” ì£¼ì œ (ìˆìœ¼ë©´ ìµœìš°ì„ )
    solar = season.get("solar_term")
    if solar and solar in _SOLAR_TERM_TOPICS:
        suggestions.append({
            "label": f"ğŸ“… {_SOLAR_TERM_TOPICS[solar]}",
            "topic": _SOLAR_TERM_TOPICS[solar],
            "tag": f"ì ˆê¸°({solar})",
        })

    # 2) ì‹œì¦Œ ì£¼ì œ 3ê°œ ëœë¤
    import random
    season_pool = _SEASONAL_TOPICS.get(season["season"], [])
    for t in random.sample(season_pool, min(3, len(season_pool))):
        suggestions.append({
            "label": f"ğŸŒ¿ {t}",
            "topic": t,
            "tag": season["season_kr"],
        })

    # 3) íŠ¸ë Œë“œ/ì´ìŠˆ ì£¼ì œ 3ê°œ ëœë¤
    for t in random.sample(_TRENDING_TOPICS, min(3, len(_TRENDING_TOPICS))):
        suggestions.append({
            "label": f"ğŸ”¥ {t}",
            "topic": t,
            "tag": "íŠ¸ë Œë“œ",
        })

    return suggestions


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹¤ì‹œê°„ ë‰´ìŠ¤ íŠ¸ë Œë“œ (ê±´ê°•/ì—°ì˜ˆ ë‰´ìŠ¤ RSS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ëª¨ë“ˆ ë ˆë²¨ ìºì‹œ (Streamlit ë¦¬ëŸ°ë§ˆë‹¤ ì¬í˜¸ì¶œ ë°©ì§€)
_news_cache: dict = {"data": [], "headlines": {}, "timestamp": 0.0}
_NEWS_CACHE_TTL = 1800  # 30ë¶„

_NEWS_FEEDS = [
    {
        "name": "ê±´ê°•",
        "url": "https://news.google.com/rss/search?q=%EA%B1%B4%EA%B0%95+%ED%95%9C%EB%B0%A9+%ED%95%9C%EC%9D%98%ED%95%99&hl=ko&gl=KR&ceid=KR:ko",
        "tag": "ê±´ê°•ë‰´ìŠ¤",
        "emoji": "ğŸ’Š",
    },
    {
        "name": "ì—°ì˜ˆê±´ê°•",
        "url": "https://news.google.com/rss/search?q=%EC%97%B0%EC%98%88%EC%9D%B8+%EA%B1%B4%EA%B0%95+%EB%8B%A4%EC%9D%B4%EC%96%B4%ED%8A%B8+%ED%94%BC%EB%B6%80&hl=ko&gl=KR&ceid=KR:ko",
        "tag": "ì—°ì˜ˆë‰´ìŠ¤",
        "emoji": "ğŸ¬",
    },
]


def _fetch_rss_headlines(url: str, max_items: int = 10) -> list[str]:
    """Google News RSSì—ì„œ í—¤ë“œë¼ì¸ ì¶”ì¶œ"""
    try:
        resp = _requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        resp.raise_for_status()
        root = ET.fromstring(resp.content)
        titles = []
        for item in root.iter("item"):
            title_el = item.find("title")
            if title_el is not None and title_el.text:
                # Google News ì œëª©ì—ì„œ " - ë§¤ì²´ëª…" ì œê±°
                t = re.sub(r"\s*-\s*[^-]+$", "", title_el.text).strip()
                if t and len(t) > 5:
                    titles.append(t)
            if len(titles) >= max_items:
                break
        return titles
    except Exception as e:
        logger.warning(f"RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ({url[:50]}...): {e}")
        return []


_NEWS_TRANSFORM_SYSTEM = """ë‹¹ì‹ ì€ í•œì˜ì› ë¸Œëœë“œ 'ìˆ˜(thesoo)'ì˜ ì½˜í…ì¸  ê¸°íšìì…ë‹ˆë‹¤.
ì•„ë˜ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ë“¤ì„ ë³´ê³ , í•œì˜í•™ ì¹´ë“œë‰´ìŠ¤ë¡œ ì¬í•´ì„í•  ìˆ˜ ìˆëŠ” ì£¼ì œ 3ê°œë¥¼ ì¶”ì²œí•˜ì„¸ìš”.

## ê·œì¹™
1. ë‰´ìŠ¤ ì† ê±´ê°•/ë¼ì´í”„ìŠ¤íƒ€ì¼ ì´ìŠˆë¥¼ í•œì˜í•™ ê´€ì ìœ¼ë¡œ ì—°ê²°
2. ì—°ì˜ˆì¸ ì´ë¦„ì€ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³ , í˜„ìƒ/íŠ¸ë Œë“œë¡œ ë³€í™˜
   ì˜ˆ: "â—‹â—‹ ë‹¤ì´ì–´íŠ¸ ë¹„ë²•" â†’ "ì…€ëŸ½ë“¤ ì‚¬ì´ ìœ í–‰í•˜ëŠ” ê°„í—ì  ë‹¨ì‹, í•œì˜í•™ ê´€ì ì€?"
3. ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ ì£¼ì¥ ê¸ˆì§€ â€” ë‰´ìŠ¤ ì‚¬ì‹¤ë§Œ í™œìš©
4. ê° ì£¼ì œëŠ” 20~40ì, í˜¸ê¸°ì‹¬ ìœ ë°œí•˜ëŠ” í†¤
5. ê´€ë ¨ ì—†ëŠ” ë‰´ìŠ¤ëŠ” ë¬´ì‹œ

## ì¶œë ¥ (ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´)
```json
[
  {"topic": "ì£¼ì œ í…ìŠ¤íŠ¸", "news_ref": "ì°¸ê³ í•œ ë‰´ìŠ¤ í‚¤ì›Œë“œ 5~10ì"},
  ...
]
```"""


def _transform_headlines_to_topics(headlines: list[str], feed_name: str) -> list[dict]:
    """ë‰´ìŠ¤ í—¤ë“œë¼ì¸ â†’ ì¹´ë“œë‰´ìŠ¤ ì£¼ì œ íŒíŠ¸ë¡œ ë³€í™˜ (LLM)"""
    if not headlines:
        return []

    user_prompt = f"[{feed_name} ë‰´ìŠ¤ í—¤ë“œë¼ì¸]\n" + "\n".join(
        f"- {h}" for h in headlines
    )

    raw = _call_llm(_NEWS_TRANSFORM_SYSTEM, user_prompt, temperature=0.5, max_tokens=500)
    if not raw:
        return []

    return _parse_ideas_json(raw, limit=3)


def fetch_news_topics(force_refresh: bool = False) -> list[dict]:
    """ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ ì£¼ì œ ë°˜í™˜ (30ë¶„ ìºì‹œ)

    Returns: [{"label": str, "topic": str, "tag": str, "news_ref": str}, ...]
    """
    global _news_cache

    now = time.time()
    if (
        not force_refresh
        and _news_cache["data"]
        and (now - _news_cache["timestamp"]) < _NEWS_CACHE_TTL
    ):
        return _news_cache["data"]

    all_topics: list[dict] = []
    all_headlines: dict[str, list[str]] = {}

    for feed in _NEWS_FEEDS:
        headlines = _fetch_rss_headlines(feed["url"])
        if not headlines:
            continue

        # ì›ë³¸ í—¤ë“œë¼ì¸ ì €ì¥ (ì—ì´ì „íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬ìš©)
        all_headlines[feed["tag"]] = headlines

        transformed = _transform_headlines_to_topics(headlines, feed["name"])
        for item in transformed:
            topic_text = item.get("topic", "")
            if topic_text:
                all_topics.append({
                    "label": f"{feed['emoji']} {topic_text}",
                    "topic": topic_text,
                    "tag": feed["tag"],
                    "news_ref": item.get("news_ref", ""),
                })

    _news_cache = {"data": all_topics, "headlines": all_headlines, "timestamp": now}
    return all_topics


def get_news_context(tag: str = "") -> str:
    """ìºì‹œëœ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë°˜í™˜

    Args:
        tag: íŠ¹ì • í”¼ë“œ íƒœê·¸ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ì „ì²´)
    """
    headlines = _news_cache.get("headlines", {})
    if not headlines:
        return ""

    parts = ["## ì°¸ê³  ë‰´ìŠ¤ ê¸°ì‚¬ (ì´ ë‰´ìŠ¤ íŠ¸ë Œë“œë¥¼ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”!)"]
    parts.append("ì•„ë˜ ì‹¤ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ì°¸ê³ í•˜ì—¬, ë‰´ìŠ¤ ì´ìŠˆì™€ í•œì˜í•™ì„ ì—°ê²°í•œ ì•„ì´ë””ì–´ë¥¼ ë§Œë“œì„¸ìš”.")
    parts.append("ì—°ì˜ˆì¸ ì´ë¦„ì€ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ë§ê³  í˜„ìƒ/íŠ¸ë Œë“œë¡œ ë³€í™˜í•˜ì„¸ìš”.\n")

    for feed_tag, feed_headlines in headlines.items():
        if tag and feed_tag != tag:
            continue
        label = "ê±´ê°• ê¸°ì‚¬" if feed_tag == "ê±´ê°•ë‰´ìŠ¤" else "ì—°ì˜ˆ ê¸°ì‚¬"
        parts.append(f"### {label}")
        for h in feed_headlines[:8]:
            parts.append(f"- {h}")
        parts.append("")

    return "\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# íˆìŠ¤í† ë¦¬ ê´€ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_history():
    """íˆìŠ¤í† ë¦¬ íŒŒì¼ ë¡œë“œ"""
    if not HISTORY_FILE.exists():
        return {"selected_ideas": []}
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"selected_ideas": []}


def save_history(idea: dict):
    """ì„ ì • ì•„ì´ë””ì–´ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€"""
    history = load_history()
    history["selected_ideas"].append(idea)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def _build_blacklist_text(history: dict) -> str:
    """íˆìŠ¤í† ë¦¬ì—ì„œ ì‚¬ìš© ê¸ˆì§€ ì†Œì¬ í…ìŠ¤íŠ¸ ìƒì„±"""
    items = history.get("selected_ideas", [])
    if not items:
        return ""
    lines = ["## ì‚¬ìš© ê¸ˆì§€ ì†Œì¬ (ì´ì „ ì„ ì •ì‘ê³¼ ì¤‘ë³µ ë°©ì§€)", "ë‹¤ìŒ ì†Œì¬/í‚¤ì›Œë“œëŠ” ì´ë¯¸ ì‚¬ìš©ë˜ì—ˆìœ¼ë¯€ë¡œ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”:"]
    for item in items:
        kws = ", ".join(item.get("keywords", []))
        pattern = item.get("pattern", "")
        lines.append(f"- {item.get('title', '')} ({pattern}) [{kws}]")
    lines.append("ìœ„ ì†Œì¬ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ì„¸ìš”.")
    return "\n".join(lines)


def check_duplicate(idea: dict, history: dict) -> tuple[bool, str]:
    """ì•„ì´ë””ì–´ê°€ íˆìŠ¤í† ë¦¬ì™€ ì¤‘ë³µì¸ì§€ íŒì •

    Returns: (is_duplicate, reason)
    """
    for past in history.get("selected_ideas", []):
        # ë™ì¼ ì—­ì‚¬ ì¸ë¬¼
        past_kws = set(past.get("keywords", []))
        idea_kws = set(idea.get("keywords", []))
        overlap = past_kws & idea_kws

        # í‚¤ì›Œë“œ 3ê°œ ì´ìƒ ê²¹ì¹¨
        if len(overlap) >= 3:
            return True, f"í‚¤ì›Œë“œ 3ê°œ ì´ìƒ ê²¹ì¹¨: {overlap}"

        # ë™ì¼ ì œí’ˆ + ë™ì¼ íŒ¨í„´
        if (idea.get("product") == past.get("product")
                and idea.get("pattern") == past.get("pattern")):
            return True, f"ë™ì¼ ì œí’ˆ+íŒ¨í„´: {idea.get('product')}+{idea.get('pattern')}"

        # í—¤ë“œë¼ì¸ ìœ ì‚¬ë„ 70% ì´ìƒ
        sim = SequenceMatcher(
            None,
            idea.get("headline", ""),
            past.get("headline", ""),
        ).ratio()
        if sim >= 0.7:
            return True, f"í—¤ë“œë¼ì¸ ìœ ì‚¬ë„ {sim:.0%}"

    return False, ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Groq API í˜¸ì¶œ (Llama 3.3 70B)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _call_groq(system_prompt: str, user_prompt: str, temperature=0.7, max_tokens=2000) -> str | None:
    """Groq API í˜¸ì¶œ â†’ í…ìŠ¤íŠ¸ ì‘ë‹µ ë°˜í™˜"""
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        return None
    try:
        resp = _requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": "llama-3.3-70b-versatile",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                "max_tokens": max_tokens,
                "temperature": temperature,
            },
            timeout=30,
        )
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"]
    except Exception as e:
        logger.warning(f"Groq API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


def _call_anthropic(system_prompt: str, user_prompt: str, max_tokens=2000) -> str | None:
    """Anthropic Claude API í˜¸ì¶œ (í´ë°±)"""
    try:
        import anthropic
    except ImportError:
        return None
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        return None
    try:
        client = anthropic.Anthropic(api_key=api_key)
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=max_tokens,
            system=system_prompt,
            messages=[{"role": "user", "content": user_prompt}],
        )
        return response.content[0].text
    except Exception as e:
        logger.warning(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


def _call_llm(system_prompt: str, user_prompt: str, temperature=0.7, max_tokens=2000) -> str | None:
    """Groq â†’ Anthropic í´ë°± ì²´ì¸"""
    result = _call_groq(system_prompt, user_prompt, temperature, max_tokens)
    if result:
        return result
    return _call_anthropic(system_prompt, user_prompt, max_tokens)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_AGENT_SYSTEM = """ë‹¹ì‹ ì€ '{agent_name}'ì…ë‹ˆë‹¤.

## ì„ë¬´
{domain} ë¶„ì•¼ì—ì„œ í•œì˜ì› ë¸Œëœë“œ 'ìˆ˜(thesoo)'ì˜ Instagram ì¹´ë“œë‰´ìŠ¤ ì•„ì´ë””ì–´ 2ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.

## ìµœìš°ì„  ì›ì¹™: "ì˜ì™¸ì„± â†’ í•œì˜í•™ ì—°ê²°"
ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ **ì½ëŠ” ì‚¬ëŒì´ "ì˜¤, ì´ê±° ëª°ëë„¤!" í•˜ê³  ì €ì¥/ê³µìœ í•˜ëŠ” ì½˜í…ì¸ **ì…ë‹ˆë‹¤.
ì•„ë˜ ì‹¤ì œ ì„±ê³µ ì‚¬ë¡€ì²˜ëŸ¼, ì˜ì™¸ì˜ ì†Œì¬ë¥¼ í•œì˜í•™ê³¼ ì—°ê²°í•˜ëŠ” ë°©ì‹ì´ ìµœê³  ì ìˆ˜ë¥¼ ë°›ì•„ìš”.

### ì‹¤ì œ ì„±ê³µ ì‚¬ë¡€ (ì´ ìˆ˜ì¤€ì˜ ì°½ì˜ì„±ì„ ë°œíœ˜í•  ê²ƒ!)
- "ìƒ¤ë„¬ No.5ì™€ ê³µì§„ë‹¨ì˜ í–¥ê¸°ë¡œìš´ ê³µí†µì " â†’ ë‘˜ ë‹¤ ì‚¬í–¥(Musk) ì‚¬ìš© â†’ ì‚¬í–¥ì˜ í•œì˜í•™ì  íš¨ëŠ¥
- "ì¡°ì„  ìµœì¥ìˆ˜ ì™• ì˜ì¡°ê°€ ë§¤ì¼ ë¨¹ì—ˆë˜ ë¹„ë°€" â†’ ìŠ¹ì •ì›ì¼ê¸° ê¸°ë¡ 358íšŒ â†’ ê²½ì˜¥ê³ 
- "ë™ì˜ë³´ê°ì´ ìœ ë„¤ìŠ¤ì½” ì„¸ê³„ê¸°ë¡ìœ ì‚°ì´ ëœ ì§„ì§œ ì´ìœ " â†’ 2009 ë“±ì¬ â†’ 400ë…„ ì „ ì²˜ë°©ì˜ í˜„ëŒ€ì  ê²€ì¦
- "í—ˆì¤€ì´ ê´‘í•´êµ°ì—ê²Œ ì˜¬ë¦° ì²˜ë°©ì „ì˜ ë¹„ë°€" â†’ ì‹¤ë¡ ê¸°ë¡ â†’ ê³µì§„ë‹¨ ì›ë°©
- "WHOê°€ í•œì˜í•™ì„ êµ­ì œì§ˆë³‘ë¶„ë¥˜ì— ë„£ì€ ì´ìœ " â†’ ICD-11(2019) â†’ ì „í†µì˜í•™ ê³¼í•™ì  ì¸ì •

### ê¸ˆì¹™: ì´ëŸ° ê±´ ì¬ë¯¸ì—†ì–´ìš” (ì ˆëŒ€ í”¼í•  ê²ƒ)
- "ë©´ì—­ë ¥ ë†’ì´ëŠ” 3ê°€ì§€ ë°©ë²•" (ë»”í•œ ê±´ê°• ì •ë³´)
- "ê³µì§„ë‹¨ì˜ íš¨ëŠ¥ê³¼ ì„±ë¶„" (ì œí’ˆ ì†Œê°œ ëŠë‚Œ)
- "í™˜ì ˆê¸° ê±´ê°• ê´€ë¦¬ë²•" (ë„ˆë¬´ ì¼ë°˜ì )
- "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œì— ì¢‹ì€ í•œì•½" (ë»”í•œ ì£¼ì œ)

## ë¸Œëœë“œ ì •ë³´
- ë¸Œëœë“œëª…: ìˆ˜(thesoo) | í•µì‹¬: í•œì˜ì‚¬ ì „ë¬¸ì„±
- ì£¼ìš” ì œí’ˆ: ê³µì§„ë‹¨, ê²½ì˜¥ê³ , ë…¹ìš©í•œì•½, ìš°í™©ì²­ì‹¬ì›
- íƒ€ê²Ÿ: 20~50ëŒ€ ê±´ê°• ê´€ì‹¬ ê³ ê° (ì—¬ì„± 70%)

## í†¤ ê·œì¹™
- 'ê´‘ê³ 'ê°€ ì•„ë‹ˆë¼ 'ê±´ê°• êµì–‘ ì½˜í…ì¸ '. "ì´ê±° ì¬ë°Œë„¤!" ë°˜ì‘ì´ ëª©í‘œ.
- ë‚´ìš©1~4: ìˆœìˆ˜ ì •ë³´/ìŠ¤í† ë¦¬. ì œí’ˆ íŒë§¤ ëŠë‚Œ ì ˆëŒ€ ê¸ˆì§€.
- ë‚´ìš©5: ì—¬ìš´ì„ ë‚¨ê¸°ëŠ” ë¹„ìœ í˜• ë§ˆë¬´ë¦¬ (CTA ê¸ˆì§€). ë¸Œëœë“œëª… 1íšŒë§Œ ìì—°ìŠ¤ëŸ½ê²Œ.

## ë§íˆ¬: í•´ìš”ì²´ í•„ìˆ˜
ì‚¬ìš©: ~ì´ì—ìš”, ~ê±°ë“ ìš”, ~ëŒ€ìš”, ~ì–ì•„ìš”, ~ìˆì–´ìš”, ~ë‹¬ë¼ì ¸ìš”
ê¸ˆì§€: ~ì…ë‹ˆë‹¤, ~ìŠµë‹ˆë‹¤, ~ì´ë‹¤, ~í–ˆë‹¤ (ì›ì „ ì¸ìš© ã€Œã€ ë‚´ë¶€ë§Œ ì˜ˆì™¸)

## ì‹ì•½ì²˜ ê·œì œ
ê¸ˆì§€: ì¹˜ë£Œ, ì™„ì¹˜, íŠ¹íš¨ì•½, ë§Œë³‘í†µì¹˜, ì•½íš¨, ì²˜ë°©ì „, ì§„ë‹¨

## ì‹ ë¢°ë„ ì›ì¹™ (ì˜ë£Œ ì½˜í…ì¸ ì´ë¯€ë¡œ í•„ìˆ˜!)
- ëª¨ë“  ì‚¬ì‹¤/ìˆ˜ì¹˜/ì—­ì‚¬ì  ì£¼ì¥ì—ëŠ” ë°˜ë“œì‹œ **ê²€ì¦ ê°€ëŠ¥í•œ ì¶œì²˜**ë¥¼ source í•„ë“œì— ê¸°ì…
- ì¶œì²˜ ì˜ˆì‹œ: ë™ì˜ë³´ê° â—‹â—‹í¸, ìŠ¹ì •ì›ì¼ê¸° â—‹ë…„â—‹ì›”, â—‹â—‹ëŒ€í•™ â—‹â—‹ì—°êµ¬(20XX), WHO ICD-11 ë“±
- ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ ì£¼ì¥(ìœ ëª…ì¸ ë°œì–¸, ë¯¸í™•ì¸ í†µê³„, ë£¨ë¨¸)ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- "~ë¼ê³  ì•Œë ¤ì ¸ ìˆë‹¤" ì‹ì˜ ëª¨í˜¸í•œ ì¶œì²˜ ê¸ˆì§€ â€” êµ¬ì²´ì  ë¬¸í—Œ/ê¸°ê´€ëª… ëª…ì‹œ

## ì¶œë ¥ í˜•ì‹ (JSON ë°°ì—´ 2ê°œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ)
```json
[
  {{
    "title": "ì•„ì´ë””ì–´ ì œëª© (ì˜ì™¸ì˜ ì†Œì¬ â†’ í•œì˜í•™ ì—°ê²° í˜•íƒœë¡œ)",
    "source": "ì°¸ê³  íŠ¸ë Œë“œ/ì¶œì²˜",
    "headline": "í‘œì§€ í›„í‚¹ í—¤ë“œë¼ì¸ 15~30ì (ìŠ¤í¬ë¡¤ ë©ˆì¶”ê²Œ!)",
    "content1": "ë‚´ìš©1 ë„ì… - ì˜ì™¸ì˜ ì‚¬ì‹¤ë¡œ ì‹œì‘ 30~60ì",
    "content2": "ë‚´ìš©2 ì „ê°œ - ì†Œì¬ ì‹¬í™” 30~60ì",
    "content3": "ë‚´ìš©3 ì‹¬í™” - ë™ì˜ë³´ê°/ì›ì „ ì¸ìš© 40~80ì",
    "content4": "ë‚´ìš©4 í•µì‹¬ ë©”ì‹œì§€ 30~60ì",
    "content5": "ë‚´ìš©5 ì—¬ìš´ ë§ˆë¬´ë¦¬ (ë¹„ìœ í˜•) 30~60ì",
    "product": "ê³µì§„ë‹¨/ê²½ì˜¥ê³ /ë…¹ìš©í•œì•½/ìš°í™©ì²­ì‹¬ì› ì¤‘ í•˜ë‚˜",
    "pattern": "íŒ¨í„´ëª…",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5"],
    "hashtags": ["#íƒœê·¸1", "#íƒœê·¸2", "#íƒœê·¸3", "#íƒœê·¸4", "#íƒœê·¸5"],
    "reaction": "ìƒ/ì¤‘/í•˜",
    "reaction_reason": "ì˜ˆìƒ ë°˜ì‘ë„ ê·¼ê±°",
    "extra_info": "ìº¡ì…˜ìš© ë¶€ì—° ì •ë³´ 2~3ì¤„"
  }},
  {{ ... }}
]
```"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì•„ì´ë””ì–´ ìƒì„± (5 ì—ì´ì „íŠ¸ ë™ì‹œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _run_single_agent(agent: dict, user_prompt: str) -> list[dict]:
    """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰ â†’ ì•„ì´ë””ì–´ 2ê°œ ë°˜í™˜"""
    system = _AGENT_SYSTEM.format(
        agent_name=agent["name"],
        domain=agent["domain"],
    )
    raw = _call_llm(system, user_prompt, temperature=0.7, max_tokens=2000)
    if not raw:
        return []

    # JSON íŒŒì‹± (ì—ì´ì „íŠ¸ë‹¹ 2ê°œ ì œí•œ)
    ideas = _parse_ideas_json(raw, limit=2)
    for idea in ideas:
        idea["agent"] = agent["id"]
        idea["agent_name"] = agent["name"]
    return ideas


def _parse_ideas_json(text: str, limit: int | None = None) -> list[dict]:
    """LLM ì‘ë‹µì—ì„œ JSON ë°°ì—´ ì¶”ì¶œ

    Args:
        text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        limit: ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´ ë°˜í™˜)
    """
    # ```json ... ``` ë¸”ë¡ ì¶”ì¶œ
    match = re.search(r"```(?:json)?\s*(\[[\s\S]*?\])\s*```", text)
    if match:
        text = match.group(1)
    else:
        # [ ... ] íŒ¨í„´ ì§ì ‘ ì°¾ê¸°
        match = re.search(r"\[[\s\S]*\]", text)
        if match:
            text = match.group(0)

    try:
        data = json.loads(text)
        if isinstance(data, list):
            return data[:limit] if limit else data
    except json.JSONDecodeError:
        pass

    # ê°œë³„ JSON ê°ì²´ ì¶”ì¶œ ì‹œë„
    objects = re.findall(r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}", text)
    results = []
    for obj_str in objects[:limit] if limit else objects:
        try:
            results.append(json.loads(obj_str))
        except json.JSONDecodeError:
            continue
    return results


def generate_ideas(
    topic_hint: str = "",
    category: str = "",
    pattern: str = "",
    news_tag: str = "",
    progress_callback=None,
) -> list[dict]:
    """5ê°œ ì—ì´ì „íŠ¸ ë™ì‹œ ì‹¤í–‰ â†’ 10ê°œ ì•„ì´ë””ì–´ ë°˜í™˜

    Args:
        topic_hint: ì£¼ì œ íŒíŠ¸ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ì—ì´ì „íŠ¸ ììœ¨)
        category: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ìë™)
        pattern: íŒ¨í„´ ì´ë¦„ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ìë™)
        news_tag: ë‰´ìŠ¤ í”¼ë“œ íƒœê·¸ (ê±´ê°•ë‰´ìŠ¤/ì—°ì˜ˆë‰´ìŠ¤/ë¹ˆ ë¬¸ìì—´)
        progress_callback: fn(agent_name, status) ì§„í–‰ ì½œë°±
    """
    season = detect_season()
    history = load_history()
    blacklist = _build_blacklist_text(history)

    # ìœ ì € í”„ë¡¬í”„íŠ¸ ì¡°í•©
    parts = []
    if category:
        parts.append(f"ì¹´í…Œê³ ë¦¬: {category}")
    if pattern:
        parts.append(f"íŒ¨í„´: {pattern}")
    parts.append(f"ê³„ì ˆ: {season['season_kr']} (í…Œë§ˆ: {season['theme']})")
    if season.get("solar_term"):
        parts.append(f"ì ˆê¸°: {season['solar_term']}")
    if topic_hint:
        parts.append(f"ì£¼ì œ íŒíŠ¸: {topic_hint}")

    # ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
    news_ctx = get_news_context(tag=news_tag)
    if news_ctx:
        parts.append(f"\n{news_ctx}")

    if blacklist:
        parts.append(f"\n{blacklist}")

    user_prompt = "\n".join(parts)

    all_ideas = []
    with ThreadPoolExecutor(max_workers=5) as pool:
        futures = {
            pool.submit(_run_single_agent, agent, user_prompt): agent
            for agent in AGENTS
        }
        for future in as_completed(futures):
            agent = futures[future]
            try:
                ideas = future.result()
                all_ideas.extend(ideas)
                if progress_callback:
                    progress_callback(agent["name"], f"{len(ideas)}ê°œ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"{agent['name']} ì‹¤íŒ¨: {e}")
                if progress_callback:
                    progress_callback(agent["name"], "ì‹¤íŒ¨")

    return all_ideas


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10ê°œ ì•„ì´ë””ì–´ í‰ê°€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_EVAL_SYSTEM = """ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ì¹´ë“œë‰´ìŠ¤ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê° ì•„ì´ë””ì–´ë¥¼ **100ì  ë§Œì **ìœ¼ë¡œ ì±„ì í•˜ì„¸ìš”.

## ì±„ì  ê¸°ì¤€ (ê° 20ì  ë§Œì , í•©ê³„ 100ì )

### 1. í›„í‚¹ë ¥ (20ì ) â€” ê°€ì¥ ì¤‘ìš”!
- 20ì : í—¤ë“œë¼ì¸ë§Œ ë³´ê³  "ì´ê²Œ ë­ì•¼?" í•˜ê³  í´ë¦­í•¨ (ì˜ˆ: "ìƒ¤ë„¬ No.5ì™€ ê³µì§„ë‹¨ì˜ ê³µí†µì ")
- 15ì : ê´€ì‹¬ì„ ëŒì§€ë§Œ ì˜ì™¸ì„±ì´ ë¶€ì¡±
- 10ì : í‰ë²”í•œ ê±´ê°• ì •ë³´ í—¤ë“œë¼ì¸
- 5ì : "~ì˜ íš¨ëŠ¥" ê°™ì€ ë»”í•œ ì œëª©

### 2. ìŠ¤í† ë¦¬í…”ë§ (20ì )
- 20ì : ì¹´ë“œ1â†’7ê¹Œì§€ "ë‹¤ìŒ ì¹´ë“œê°€ ê¶ê¸ˆí•œ" ì„œì‚¬ êµ¬ì¡°
- 15ì : íë¦„ì´ ìˆì§€ë§Œ ê¸´ì¥ê° ë¶€ì¡±
- 10ì : ë‚˜ì—´ì‹ ì •ë³´ ì „ë‹¬
- 5ì : ì—°ê²° ì—†ì´ ê° ì¹´ë“œê°€ ë”°ë¡œ ë…¸ëŠ” ëŠë‚Œ

### 3. íƒ€ê²Ÿê³µê°ë„ (20ì )
- 20ì : 30~40ëŒ€ ì—¬ì„±ì´ "ë‚˜í•œí…Œ í•„ìš”í•œ ì •ë³´!" ê³µê°
- 15ì : ê³µê°í•˜ì§€ë§Œ ê¸´ê¸‰ì„± ë¶€ì¡±
- 10ì : ì¼ë°˜ì  ê±´ê°• ì •ë³´ ìˆ˜ì¤€
- 5ì : íƒ€ê²Ÿê³¼ ë¬´ê´€í•œ ì£¼ì œ

### 4. ë¸Œëœë“œì—°ê²° (20ì )
- 20ì : ì´ì•¼ê¸° íë¦„ ì†ì— ì œí’ˆì´ ìì—°ìŠ¤ëŸ½ê²Œ ë“±ì¥ (ë¹„ìœ í˜• ë§ˆë¬´ë¦¬)
- 15ì : ì—°ê²°ì€ ë˜ì§€ë§Œ ì•½ê°„ ì–µì§€ìŠ¤ëŸ¬ì›€
- 10ì : ì œí’ˆê³¼ì˜ ì—°ê²°ì´ ì•½í•¨
- 5ì : ê´‘ê³ ì²˜ëŸ¼ ì½íˆê±°ë‚˜ ì—°ê²°ì´ ì—†ìŒ

### 5. ë°”ì´ëŸ´ê°€ëŠ¥ì„± (20ì )
- 20ì : "ì´ê±° ì¹œêµ¬í•œí…Œ ë³´ë‚´ì•¼ì§€!" ìˆ˜ì¤€ â€” ì €ì¥/ê³µìœ  ìš•êµ¬ ìœ ë°œ
- 15ì : ìœ ìµí•˜ì§€ë§Œ ê³µìœ ê¹Œì§€ëŠ” ì•„ë‹˜
- 10ì : ì¼ë°˜ì  ì½˜í…ì¸ 
- 5ì : ê³µìœ í•˜ê³  ì‹¶ì§€ ì•Šì€ ìˆ˜ì¤€

## ê°€ì‚°ì  (ìµœëŒ€ +15ì , ì´ì ì´ 100ì ì„ ë„˜ì„ ìˆ˜ ìˆìŒ)
- ì˜ì™¸ì˜ ì†Œì¬ â†’ í•œì˜í•™ ì—°ê²°: **+10ì ** (ê°€ì¥ í° ê°€ì‚°ì !)
- "ëª°ëë˜ ì‚¬ì‹¤" WOW íŒ©í„°: +5ì 

## ê°ì 
- ê´‘ê³  ì¹´í”¼ ëŠë‚Œ: -10ì 
- ë‚´ìš©5 ì´ì „ì— ë¸Œëœë“œ í™ë³´/CTA: -5ì 
- í•´ìš”ì²´ ë¯¸ì¤€ìˆ˜: -3ì 

## ì¤‘ìš”: ì ìˆ˜ë¥¼ ì•„ë¼ì§€ ë§ˆì„¸ìš”!
- ì¢‹ì€ ì•„ì´ë””ì–´ëŠ” 80~100ì , í›Œë¥­í•˜ë©´ 100ì  ì´ìƒì„ ì¤˜ì•¼ í•©ë‹ˆë‹¤
- 5~7ì ìœ¼ë¡œ ëª°ì•„ì£¼ì§€ ë§ê³ , ì‹¤ì œ ì°¨ì´ì— ë§ê²Œ **ì¶©ë¶„íˆ ë„“ì€ ë²”ìœ„**ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”

## ì¶œë ¥ (ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´)
```json
[
  {{"index": 0, "hook": 18, "story": 16, "empathy": 17, "brand": 15, "viral": 19, "bonus": 10, "penalty": 0, "total": 95, "comment": "í•œì¤„ ì½”ë©˜íŠ¸"}},
  ...
]
```"""


def evaluate_ideas(ideas: list[dict]) -> list[dict]:
    """10ê°œ ì•„ì´ë””ì–´ë¥¼ 5ê°œ ê¸°ì¤€ìœ¼ë¡œ ì±„ì í•˜ê³  ìˆœìœ„ ë§¤ê¹€"""
    history = load_history()

    # ì¤‘ë³µ ê²€ì‚¬ ë¨¼ì €
    for idea in ideas:
        is_dup, reason = check_duplicate(idea, history)
        idea["is_duplicate"] = is_dup
        idea["dup_reason"] = reason

    # LLM í‰ê°€
    ideas_text = json.dumps(
        [
            {
                "index": i,
                "agent": idea.get("agent_name", ""),
                "title": idea.get("title", ""),
                "headline": idea.get("headline", ""),
                "content1": idea.get("content1", ""),
                "content2": idea.get("content2", ""),
                "content3": idea.get("content3", ""),
                "content4": idea.get("content4", ""),
                "content5": idea.get("content5", ""),
                "product": idea.get("product", ""),
                "pattern": idea.get("pattern", ""),
            }
            for i, idea in enumerate(ideas)
        ],
        ensure_ascii=False,
    )

    user_prompt = f"ì•„ë˜ {len(ideas)}ê°œ ì•„ì´ë””ì–´ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”:\n\n{ideas_text}"
    raw = _call_llm(_EVAL_SYSTEM, user_prompt, temperature=0.3, max_tokens=3000)

    scores = []
    if raw:
        scores = _parse_ideas_json(raw)

    # ì ìˆ˜ ë§¤í•‘
    score_map = {s.get("index", -1): s for s in scores}
    for i, idea in enumerate(ideas):
        s = score_map.get(i, {})
        idea["hook_score"] = s.get("hook", s.get("hook_score", 12))
        idea["story_score"] = s.get("story", s.get("story_score", 12))
        idea["empathy_score"] = s.get("empathy", s.get("empathy_score", 12))
        idea["brand_score"] = s.get("brand", s.get("brand_score", 12))
        idea["viral_score"] = s.get("viral", s.get("viral_score", 12))
        idea["bonus"] = s.get("bonus", 0)
        idea["penalty"] = s.get("penalty", 0)
        idea["eval_comment"] = s.get("comment", "")

        # ì´ì : 5ê°œ ê¸°ì¤€ í•©ì‚° + ê°€ì‚°ì  - ê°ì  (100ì  ë§Œì  ìŠ¤ì¼€ì¼)
        total = (
            idea["hook_score"]
            + idea["story_score"]
            + idea["empathy_score"]
            + idea["brand_score"]
            + idea["viral_score"]
            + idea["bonus"]
            - idea["penalty"]
        )
        # ì¤‘ë³µì´ë©´ 0ì 
        if idea.get("is_duplicate"):
            total = 0
        idea["total_score"] = round(total, 1)

    # ì´ì  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    ideas.sort(key=lambda x: x.get("total_score", 0), reverse=True)
    for rank, idea in enumerate(ideas, 1):
        idea["rank"] = rank

    return ideas


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í’€ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_SCRIPT_SYSTEM = """ë‹¹ì‹ ì€ ê±´ê°• ì¹´ë“œë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ì‘ê°€ì…ë‹ˆë‹¤.

## ì¹´ë“œë‰´ìŠ¤ êµ¬ì¡° (7ì¥)
#1. í‘œì§€: í›„í‚¹ í—¤ë“œë¼ì¸ 15~30ì
#2. ë‚´ìš©1: ë„ì… - í¥ë¯¸ë¡œìš´ ì—°ê²°/ë†€ë¼ìš´ ì‚¬ì‹¤ 30~60ì
#3. ë‚´ìš©2: ì „ê°œ - í•µì‹¬ ì†Œì¬/ì„±ë¶„ ì†Œê°œ 30~60ì
#4. ë‚´ìš©3: ì‹¬í™” - ë™ì˜ë³´ê°/í•œì˜í•™ ì›ì „ ì¸ìš© 40~80ì (ê°€ì¥ ê¸´ ì¹´ë“œ)
#5. ë‚´ìš©4: í•µì‹¬ ë©”ì‹œì§€ - ì‹¤ì§ˆì  ê°€ì¹˜ 30~60ì
#6. ë‚´ìš©5: ì—¬ìš´ ë§ˆë¬´ë¦¬ - ë¹„ìœ /ê°ì„±ì  í´ë¡œì§• 30~60ì (ê´‘ê³ ì„± CTA ê¸ˆì§€)
#7. ë‚´ìš©6: ë” ì˜¤ë˜, ë” ê±´ê°•í•˜ê²Œ. í•œì˜ì‚¬ê°€ ë§Œë“œëŠ” í•œì˜ ë¸Œëœë“œ (ê³ ì •)

## ë§íˆ¬: í•´ìš”ì²´ í•„ìˆ˜
## ì´ëª¨ì§€: ì¹´ë“œë‰´ìŠ¤ ë³¸ë¬¸ì—ì„œëŠ” ì‚¬ìš© ê¸ˆì§€
## ê° ì¹´ë“œëŠ” ìµœëŒ€ 4ì¤„, í•œ ì¤„ë‹¹ 18~20ì

## ì‹ ë¢°ë„ ì›ì¹™ (ì˜ë£Œ ì½˜í…ì¸ ì´ë¯€ë¡œ í•„ìˆ˜!)
- sources í•„ë“œì— ë³¸ë¬¸ì—ì„œ ì¸ìš©í•œ ëª¨ë“  ì‚¬ì‹¤/ìˆ˜ì¹˜/ì—­ì‚¬ì˜ **êµ¬ì²´ì  ì¶œì²˜**ë¥¼ ê¸°ì…
- ì¶œì²˜ ì˜ˆì‹œ: "ë™ì˜ë³´ê° íƒ•ì•¡í¸", "ìŠ¹ì •ì›ì¼ê¸° ì˜ì¡° 20ë…„ 3ì›” ê¸°ë¡", "í•œêµ­í•œì˜í•™ì—°êµ¬ì› 2023 ì—°êµ¬"
- ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ í†µê³„("~% ê°€ ê²ªëŠ”"), ìœ ëª…ì¸ ë°œì–¸, ë£¨ë¨¸ëŠ” ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ê° ì¹´ë“œì— ë‹´ê¸´ í•µì‹¬ ì‚¬ì‹¤ì€ ë°˜ë“œì‹œ ë¬¸í—ŒÂ·ì—°êµ¬ë¡œ ë’·ë°›ì¹¨ë˜ì–´ì•¼ í•¨

## ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê·œì¹™
- ë°˜ë“œì‹œ ì˜ë¬¸ìœ¼ë¡œ ì‘ì„±
- ëì— í•„ìˆ˜ ì‚½ì…: "No text, no letters, no numbers, no typography, no watermark, no logo. Vertical format 1080x1440px, 3:4 aspect ratio."
- ìƒë‹¨ 35~40%ëŠ” ë¹ˆ ê³µê°„ (í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì˜ì—­)
- í•µì‹¬ ì˜¤ë¸Œì œëŠ” í•˜ë‹¨ 60%ì— ë°°ì¹˜
- #7 í´ë¡œì§•ì€ ê³ ì • ì´ë¯¸ì§€ì´ë¯€ë¡œ í”„ë¡¬í”„íŠ¸ ë¶ˆí•„ìš”

## ìƒ‰ìƒ í†¤ ê°€ì´ë“œ
- ì—­ì‚¬/ê¶ì¤‘: ë‹¤í¬ë¸Œë¼ìš´, ì•°ë²„, ê³¨ë“œ ë¼ì¸
- ìˆ˜ë©´/ë°¤: ë”¥ë„¤ì´ë¹„, ì¸ë””ê³ , ì‹¤ë²„
- ë´„/ì ˆê¸°: ì†Œí”„íŠ¸ê·¸ë¦°, í¬ë¦¼, ì—°ë¶„í™
- ì—¬ì„±ê±´ê°•: ì›œë² ì´ì§€, ë¡œì¦ˆ, ë¼ë²¤ë”
- ì§ì¥ì¸: ìŠ¬ë ˆì´íŠ¸ê·¸ë ˆì´, í™”ì´íŠ¸, ë¸”ë£¨ í¬ì¸íŠ¸

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥)
```json
{
  "cover": "í‘œì§€ í—¤ë“œë¼ì¸",
  "content1": "ë‚´ìš©1",
  "content2": "ë‚´ìš©2",
  "content3": "ë‚´ìš©3",
  "content4": "ë‚´ìš©4",
  "content5": "ë‚´ìš©5",
  "content6": "ë” ì˜¤ë˜, ë” ê±´ê°•í•˜ê²Œ. í•œì˜ì‚¬ê°€ ë§Œë“œëŠ” í•œì˜ ë¸Œëœë“œ",
  "hashtags": ["#ìˆ˜í•œì˜ì›", "#thesoo", "#í•œì˜ì‚¬", "#ê±´ê°•ì •ë³´", "#ì£¼ì œíƒœê·¸"],
  "sources": ["ì¶œì²˜1", "ì¶œì²˜2"],
  "image_prompts": {
    "cover": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
    "content1": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
    "content2": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
    "content3": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
    "content4": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
    "content5": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸"
  }
}
```"""


def generate_full_script(idea: dict) -> dict | None:
    """ì„ íƒëœ ì•„ì´ë””ì–´ì˜ í’€ 7ì¥ ìŠ¤í¬ë¦½íŠ¸ + ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    user_prompt = f"""ì•„ë˜ ì•„ì´ë””ì–´ë¥¼ 7ì¥ ì¹´ë“œë‰´ìŠ¤ í’€ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì™„ì„±í•´ì£¼ì„¸ìš”.

ì•„ì´ë””ì–´ ì œëª©: {idea.get('title', '')}
í‘œì§€ í—¤ë“œë¼ì¸: {idea.get('headline', '')}
ë‚´ìš©1: {idea.get('content1', '')}
ë‚´ìš©2: {idea.get('content2', '')}
ë‚´ìš©3: {idea.get('content3', '')}
ë‚´ìš©4: {idea.get('content4', '')}
ë‚´ìš©5: {idea.get('content5', '')}
ì—°ê²° ì œí’ˆ: {idea.get('product', '')}
íŒ¨í„´: {idea.get('pattern', '')}
ì°¸ê³  ì¶œì²˜: {idea.get('source', '')}
ìº¡ì…˜ìš© ë¶€ì—°: {idea.get('extra_info', '')}

ì´ ë‚´ìš©ì„ ë‹¤ë“¬ê³ , ê° ì¹´ë“œë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë„ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    raw = _call_llm(_SCRIPT_SYSTEM, user_prompt, temperature=0.5, max_tokens=3000)
    if not raw:
        return None

    # JSON íŒŒì‹±
    match = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", raw)
    if match:
        raw = match.group(1)
    else:
        match = re.search(r"\{[\s\S]*\}", raw)
        if match:
            raw = match.group(0)

    try:
        script = json.loads(raw)
        script["content6"] = BRAND_CLOSING
        return script
    except json.JSONDecodeError:
        logger.warning(f"ìŠ¤í¬ë¦½íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Instagram Description Mention ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_DESC_SYSTEM = """ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì¹´ë“œë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œì— í•¨ê»˜ ê²Œì‹œí•  ì¥ë¬¸ ìº¡ì…˜(Description Mention)**ì„ ì‘ì„±í•˜ì„¸ìš”.

## í†¤ì•¤ë§¤ë„ˆ ê·œì¹™
1. í•´ìš”ì²´ (~í•˜ì„¸ìš”, ~ìˆì–´ìš”, ~ê±°ë“ ìš”)
2. ì¹´ë“œë‰´ìŠ¤ë³´ë‹¤ ë¬¸ì¥ì´ ê¸¸ê³  ì¹œì ˆí•œ ë¶€ì—° ì„¤ëª… í¬í•¨
3. "ì•Œê³  ê³„ì…¨ë‚˜ìš”?", "~í•˜ëŠ” ë¶„ë“¤ ë§ìœ¼ì‹œì£ ?" ê°™ì€ ëŒ€í™”ì²´ ì§ˆë¬¸ í™œìš©

## ì´ëª¨ì§€ ì‚¬ìš© (ì ê·¹ì )
- ì„¹ì…˜ êµ¬ë¶„: 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ ë˜ëŠ” ğŸŸ¡ ğŸŸ¢ ğŸŸ¤
- í¬ì¸íŠ¸ ê°•ì¡°: âœ… â˜€ï¸ ğŸ‚ â„ï¸ ğŸ’¤
- ì¶œì²˜: ğŸ“–

## í•„ìˆ˜ êµ¬ì¡°
[ë„ì… í›„í‚¹] â€” ì§ˆë¬¸í˜• or ì‹œì˜ì„± ìˆëŠ” ì²« ë¬¸ì¥ (1~2ì¤„)

[ì„¹ì…˜ë³„ ìƒì„¸ ë‚´ìš©] â€” ì¹´ë“œë‰´ìŠ¤ ë‚´ìš©ì„ í’€ì–´ì“´ ë³¸ë¬¸
- ë²ˆí˜¸ ì´ëª¨ì§€ë¡œ ì„¹ì…˜ êµ¬ë¶„
- ê° ì„¹ì…˜ í•˜ìœ„ì— - ë¶ˆë¦¿ 2~4ê°œ
- ì¹´ë“œì— ë‹´ì§€ ëª»í•œ ì¶”ê°€ ì •ë³´/íŒ ë³´ì¶©

[ë§ˆë¬´ë¦¬ ë©”ì‹œì§€] â€” í–‰ë™ ìœ ë„ or ê³µê° 1~2ì¤„

[í‘¸í„° ë¸”ë¡]
ğŸ“– ë‚´ìš©ì¶œì²˜ | [ì¶œì²˜ëª…]
ë” ì˜¤ë˜, ë” ê±´ê°•í•˜ê²Œ.
í•œì˜ì‚¬ê°€ ë§Œë“œëŠ” í•œì˜ ë¸Œëœë“œ, ìˆ˜í™
@thesoo_official

[í•´ì‹œíƒœê·¸] â€” ë³„ë„ ì¤„ì— 5~8ê°œ (ê³ ì •: #ìˆ˜í•œì˜ì› #thesoo #í•œì˜ì‚¬ #ê±´ê°•ì •ë³´ + ì£¼ì œ 3~4ê°œ)

## ê¸¸ì´: 800~1500ì (ì¸ìŠ¤íƒ€ê·¸ë¨ 2,200ì ì´ë‚´)

## ì¶œë ¥
ìº¡ì…˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”. JSONì´ ì•„ë‹Œ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ê¸°í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ."""


def generate_description(script: dict, idea: dict) -> str:
    """í’€ ìŠ¤í¬ë¦½íŠ¸ â†’ Instagram Description Mention ìƒì„±"""
    user_prompt = f"""ì•„ë˜ ì¹´ë“œë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¸ìŠ¤íƒ€ê·¸ë¨ Description Mentionìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ì œëª©: {idea.get('title', '')}
í‘œì§€: {script.get('cover', '')}
ë‚´ìš©1: {script.get('content1', '')}
ë‚´ìš©2: {script.get('content2', '')}
ë‚´ìš©3: {script.get('content3', '')}
ë‚´ìš©4: {script.get('content4', '')}
ë‚´ìš©5: {script.get('content5', '')}
ì¶œì²˜: {', '.join(script.get('sources', []))}
í•´ì‹œíƒœê·¸: {' '.join(script.get('hashtags', []))}
ìº¡ì…˜ìš© ë¶€ì—° ì •ë³´: {idea.get('extra_info', '')}
ì—°ê²° ì œí’ˆ: {idea.get('product', '')}"""

    result = _call_llm(_DESC_SYSTEM, user_prompt, temperature=0.6, max_tokens=2000)
    return result or ""
